{
  "header": {
    "title": "Dive AI"
  },
  "chat": {
    "placeholder": "Type a message...",
    "newChat": "New Chat",
    "history": "History",
    "copyCode": "Copy",
    "previewCode": "Click to preview",
    "uploadFile": "Upload file",
    "send": "Send",
    "untitledChat": "Untitled Chat",
    "deleteChat": "Delete Chat",
    "deleteSuccess": "Chat deleted",
    "deleteFailed": "Failed to delete",
    "confirmDelete": "Confirm Delete",
    "tools": "Tools",
    "abort": "Stop generating response",
    "retry": "Retry"
  },
  "welcome": {
    "title": "Welcome to Dive AI",
    "subtitle": "Start your AI conversation",
    "startChat": "Start Chat"
  },
  "setup": {
    "title": "Initial Setup",
    "subtitle": "Please configure model settings",
    "required": "This field is required",
    "submit": "Save Settings",
    "provider": "Model Provider",
    "verify": "Verify Model",
    "verifySuccess": "Model verification successful",
    "verifySuccessNoTool": "Model verification successful, but does not support MCP Tool Calls",
    "verifyFailed": "Model verification failed",
    "verifyError": "Error occurred during verification",
    "saveSuccess": "Settings saved successfully",
    "saveFailed": "Failed to save settings",
    "back": "Back",
    "parameters": "Parameters",
    "topPDescription": "Top P is a parameter that controls the diversity of text generated by the GPT model. When generating text, the model calculates probability distributions for each generated word or token in the vocabulary. Top P controls how many of the highest probability words or tokens are selected for text generation. For example, if top_p=0.9, the threshold is set to include tokens that cumulatively add up to 90% of the probability mass.",
    "temperatureDescription": "Temperature is a parameter that controls the 'creativity' or randomness of text generated by the GPT model. A higher temperature (e.g., 0.7) leads to more diverse and innovative outputs, while a lower temperature (e.g., 0.2) makes the output more deterministic and focused."
  },
  "sidebar": {
    "tools": "Tools Management(MCP)",
    "settings": "Model Settings"
  },
  "tools": {
    "title": "Tools Management(MCP)",
    "subtitle": "Tools and settings for MCP Server",
    "editConfig": "Edit Config",
    "configTitle": "MCP Server Configuration",
    "save": "Save",
    "cancel": "Cancel",
    "saveSuccess": "Settings saved successfully",
    "saveFailed": "Failed to save settings",
    "openConfigFolder": "Open Config Folder",
    "addServer": "Add MCP Server",
    "addServerTitle": "Add MCP Server",
    "addServerSubtitle": "Please paste MCP Server Json directly",
    "fetchFailed": "Failed to load tools",
    "configFetchFailed": "Failed to load configuration",
    "invalidJson": "Invalid JSON format"
  },
  "modelConfig": {
    "title": "Model Settings",
    "customInstructions": "Custom Instructions",
    "customInstructionsPlaceholder": "Enter custom model instructions...",
    "customInstructionsDescription": "These instructions are added to the end of the system prompt sent with every request.",
    "saveInstructions": "Save Instructions",
    "customRulesSaved": "Custom instructions saved",
    "customRulesFailed": "Failed to save custom instructions"
  },
  "common": {
    "close": "Close",
    "confirm": "Confirm",
    "cancel": "Cancel"
  }
} 